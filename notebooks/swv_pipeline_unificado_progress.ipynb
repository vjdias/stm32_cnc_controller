{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Unificado SWV → FOPDT → PD (com modo Progress)\n",
    "\n",
    "Este notebook reúne e aprofunda todo o pipeline de análise SWV do projeto, incluindo:\n",
    "\n",
    "1) Sanitização dos dumps SWV/ITM em CSV canônico (`filter_swv_export.py`)\n",
    "2) Cálculo de séries derivadas e métricas temporais (`analyze_step_responses.py`)\n",
    "3) Identificação FOPDT (K, L, τ) por análise de degrau\n",
    "4) Síntese de ganhos PD (Ziegler–Nichols, curva de reação) e conversão para firmware\n",
    "5) Emissão de summary + CSVs derivados\n",
    "6) Consolidação em `tuning_profiles.py`\n",
    "7) Demonstração de simulação no modo 'progress' (compat) como em `interactive_old_sim.py`\n",
    "\n",
    "Inclui fórmulas, heurísticas, checklist de diagnóstico e uma seção de **FOPDT em detalhes**. Ao final, há uma seção de **Referências** com livros e artigos clássicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sanitização (SWV → *_filtered.csv)\n",
    "\n",
    "Objetivo: transformar dumps SWV possivelmente ruidosos em CSVs consistentes com linhas do tipo:\n",
    "\n",
    "```\n",
    "axis,id,time_ms,encoder,pulses\n",
    "```\n",
    "\n",
    "Regras de consistência implementadas em `filter_swv_export.py`:\n",
    "- Aceita apenas linhas que casam uma regex numérica inteira com 5 campos.\n",
    "- `axis` é fixado pela primeira linha válida; linhas com eixo divergente são descartadas.\n",
    "- `id` deve ser estritamente crescente; `time_ms` e `pulses` não podem regredir (≥).\n",
    "- `encoder` é convertido para módulo (sempre \"positivo\").\n",
    "- Arquivo que não mantém nenhuma linha é descartado (remove-se a saída vazia).\n",
    "\n",
    "Racional: regressões em `time_ms`/`pulses` invalidam derivadas; eixo misto polui constantes físicas; `id` estrito facilita detectar perdas/duplicações."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Séries Derivadas (velocidades)\n",
    "\n",
    "Com janelas de tamanho `N` (stride):\n",
    "- $t_k = time\\_ms(k)/1000$; $\\Delta t_k = t_k - t_{k-N+1}$.\n",
    "- $v_{cmd}(k) = [pulses(k)-pulses(k-N+1)]/\\Delta t_k$.\n",
    "- $v_{enc}(k) = [encoder(k)-encoder(k-N+1)]/\\Delta t_k$.\n",
    "\n",
    "Trade-off do stride (\"N\"):\n",
    "- N pequeno: resposta rápida, porém ruído maior.\n",
    "- N grande: suave, porém pode atrasar/achatar o degrau.\n",
    "\n",
    "Dica: ajuste `--stride` conforme ruído/Δt mínimo; valide com plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Identificação FOPDT (K, L, τ)\n",
    "\n",
    "Modelo: $G_v(s) = \\dfrac{K e^{-Ls}}{\\tau s + 1}$.\n",
    "\n",
    "- Ganho estático: $K = v_{enc,ss}/v_{cmd,ss}$ (médias na janela final).\n",
    "- Tempo morto: $L = t_{enc}^{5\\%} - t_{cmd}^{5\\%}$.\n",
    "- Constante de tempo: $\\tau = t_{63} - L$, com $t_{63}$ tal que $v_{enc}(t_{63}) \\ge 0,632\\,v_{enc,ss}$.\\n",
    "\n",
    "Heurísticas de robustez:\n",
    "- Se $L \\le 0$ ou indefinido, use piso $\\min(\\Delta t)$.\\n",
    "- Se $\\tau \\le 0$ ou indefinido, idem.\\n",
    "- Descarte valores NaN/inf nas janelas.\n",
    "\n",
    "Classificação de forma do degrau (opcional): *step-like* se subida 10–90% ≤ 15% da duração; senão *ramp-like*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Síntese PD (Ziegler–Nichols, Curva de Reação)\n",
    "\n",
    "$K_p = 1{,}2 \\cdot \\dfrac{\\tau}{K\\,L}$,  $T_d = 0{,}5 L$,  $K_d = K_p T_d$,  $K_i = 0$.\\n",
    "\n",
    "- Sugestão segura: iniciar com $K_p/2$ e subir gradualmente.\n",
    "- Conversão firmware (escala 256): `kp_i = round(Kp·256)`, etc.\n",
    "- CPR do encoder: menor CPR → menor $K$ → maior $K_p$ (mantidos L, τ)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary e Artefatos\n",
    "- `analysis_summary.txt`: consolida K, L, τ, ganhos PD e estatísticas.\n",
    "- `analysis_data/*_derived.csv`: séries derivadas para auditoria.\n",
    "- Use estes arquivos para verificar thresholds, Δt mínimo e forma do degrau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Integração com `tuning_profiles.py`\n",
    "- Tabela consolidada `(axis, microstep) → (Kp, Ki, Kd, L, τ, steady_*)`.\n",
    "- Simuladores (`fopdt_simulator.py`, `interactive_sim.py`) consomem esses perfis e aplicam `K_SCALE=256`.\n",
    "- Pode-se automatizar o carregamento do `analysis_summary.txt` como melhoria futura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOPDT em detalhes\n",
    "**Modelo**: $G(s) = K e^{-L s}/(τ s + 1)$. Resposta a degrau $u_0$: $y(t)=0$ (t<L); $y(t)=K\\,u_0\\,[1 - e^{-(t - L)/τ}]$ (t≥L).\n",
    "\n",
    "- 63,2%: $t_{63} = L + τ$; 90%: $t_{90} ≈ L + 2{,}303·τ$; $t_s(±2\\%) ≈ L + 4·τ$.\n",
    "- Freq.: $|G(jω)| = K/√(1 + (ω·τ)^2)$, $φ = −arctan(ω·τ) − ω·L$. Atraso reduz margem de fase.\n",
    "- Discreto: $n_d = round(L/T_s)$, $α = 1 − e^{−T_s/τ}$, $x[k] = x[k−1] + α·(K·u[k−n_d] − x[k−1])$.\n",
    "- Identificação por degrau com thresholds (5% e 63,2%) + pisos por Δt mínimo.\n",
    "- Tuning PD (Z–N): $K_p = 1{,}2·τ/(K·L)$, $T_d = 0{,}5·L$, $K_d = K_p·T_d$.\n",
    "- Limites: processos com integrador/2ª ordem subamortecida podem exigir modelos alternativos (IDT, 2ª ordem + atraso).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Demo: Simulação no modo 'progress' (compat)\n",
    "Executa a simulação headless com as mesmas flags do `interactive_old_sim.py` (estratégia de mestre por progresso), gravando CSV e imprimindo um resumo rápido.\n",
    "\n",
    "Observação: esta célula usa as classes de `interactive_sim.py` e pode imprimir mensagens do backend do Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulação headless no modo 'progress' (compat)\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "from tuning_profiles import AnalysisCatalog\n",
    "from interactive_sim import (\n",
    "    PlantConfig, Scenario, parse_axis_map, gains_from_catalog, InteractiveSim,\n",
    ")\n",
    "\n",
    "# Eixos e microsteps (edite conforme necessidade)\n",
    "axis_map = parse_axis_map('X:256,Y:256,Z:256')\n",
    "kp_xyz, ki_xyz, kd_xyz = gains_from_catalog(axis_map)\n",
    "\n",
    "# Configuração de planta e cenário compatíveis com interactive_old_sim.py\n",
    "cfg = PlantConfig(\n",
    "    microstep_factor=axis_map[0][1],\n",
    "    enc_cpr_xyz=(40000, 2500, 40000),\n",
    "    kd_alpha_bits=8,\n",
    "    step_high_ticks=1,\n",
    "    step_low_ticks=1,\n",
    ")\n",
    "scn = Scenario(\n",
    "    s_xyz=(20000, 16000, 12000),\n",
    "    v_xyz=(10000, 8000, 6000),\n",
    "    dir_xyz=(1, 1, 1),\n",
    "    kp_xyz=kp_xyz, ki_xyz=ki_xyz, kd_xyz=kd_xyz,\n",
    "    sim_time_s=5.0,\n",
    "    use_dda=True,\n",
    ")\n",
    "\n",
    "sim = InteractiveSim(\n",
    "    cfg, scn, log_dir=Path('sim_logs'), enable_logging=True, auto_analyze=True, headless=True\n",
    ")\n",
    "\n",
    "# Flags de compatibilidade (modo 'progress')\n",
    "sim.master_select_strategy = 'progress'\n",
    "sim.prefer_loaded_master = False\n",
    "sim.master_switch_margin_steps = 0.0\n",
    "sim.sync_err_feed_threshold = 200.0\n",
    "sim.sync_err_feed_min_fraction = 0.25\n",
    "sim.sync_hold_enabled = False\n",
    "sim.finish_all_axes = False\n",
    "sim.ramp_use_worst_remaining = False\n",
    "sim.global_stop_all_axes = True\n",
    "sim.finish_window_steps = 0.0\n",
    "sim.finish_disable_stall = False\n",
    "sim.finish_extra_budget_steps = 0\n",
    "\n",
    "# Execução headless (como no interactive_old_sim)\n",
    "sim._start_log_session()\n",
    "sim._log_state(\n",
    "    t=sim.t,\n",
    "    pos_steps=sim.pos_real.copy(),\n",
    "    pos_enc=sim._encoder_rel_dda(),\n",
    "    vel_sps=sim.v_real.copy(),\n",
    "    casc_err=sim.g_casc_err_s32.copy(),\n",
    "    load_c=sim.active_C_load.copy(),\n",
    "    load_timer=sim.load_timer_xyz.copy(),\n",
    "    span_steps=0.0,\n",
    "    global_stop=False,\n",
    ")\n",
    "while sim.k < sim.N_steps_total:\n",
    "    sim._step()\n",
    "sim._stop_log_session()\n",
    "\n",
    "# Resumo do último log\n",
    "if getattr(sim, 'last_log_path', None) and sim.last_log_path.exists():\n",
    "    with sim.last_log_path.open() as f:\n",
    "        r = csv.DictReader(f)\n",
    "        rows = list(r)\n",
    "    if rows:\n",
    "        span_final = float(rows[-1]['span_steps'])\n",
    "        stop_frac = sum(int(x['global_stop']) for x in rows)/len(rows)\n",
    "        print(f'Log: {sim.last_log_path.name} | amostras={len(rows)} | span_final={span_final:.0f} | stop_frac={stop_frac:.1%}')\n",
    "else:\n",
    "    print('Sem log gerado.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Utilitários demonstrativos (K, L, τ e Z–N)\n",
    "Pequenas funções para ilustrar as mesmas fórmulas usadas nos scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import csv, math\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "\n",
    "def load_filtered_rows(csv_path: Path) -> List[Dict[str, int]]:\n",
    "    rows: List[Dict[str, int]] = []\n",
    "    with csv_path.open('r', encoding='utf-8', newline='') as fh:\n",
    "        reader = csv.reader(fh)\n",
    "        for cols in reader:\n",
    "            if len(cols) < 5: continue\n",
    "            try:\n",
    "                rows.append({'axis': int(cols[0]), 'seq': int(cols[1]), 'time_ms': int(cols[2]), 'encoder': int(cols[3]), 'pulses': int(cols[4])})\n",
    "            except:\n",
    "                pass\n",
    "    return rows\n",
    "\n",
    "def compute_raw_series(rows: List[Dict[str, int]]):\n",
    "    T: List[float] = []\n",
    "    Vc: List[float] = []\n",
    "    Ve: List[float] = []\n",
    "    dt_values: List[float] = []\n",
    "    prev = None\n",
    "    for r in rows:\n",
    "        if prev is None: prev = r; continue\n",
    "        dt_ms = r['time_ms'] - prev['time_ms']\n",
    "        if dt_ms <= 0: prev = r; continue\n",
    "        dt = dt_ms / 1000.0\n",
    "        Vc.append((r['pulses'] - prev['pulses']) / dt)\n",
    "        Ve.append((r['encoder'] - prev['encoder']) / dt)\n",
    "        T.append(r['time_ms'] / 1000.0)\n",
    "        dt_values.append(dt)\n",
    "        prev = r\n",
    "    return T, Vc, Ve, dt_values\n",
    "\n",
    "def steady_value(values: List[float], frac: float = 0.2) -> Optional[float]:\n",
    "    if not values: return None\n",
    "    start = len(values) - max(1, int(len(values) * frac))\n",
    "    window = [v for v in values[start:] if (v is not None and not math.isnan(v))]\n",
    "    if not window: window = [v for v in values if (v is not None and not math.isnan(v))]\n",
    "    if not window: return None\n",
    "    return sum(window) / len(window)\n",
    "\n",
    "def first_crossing(times: List[float], values: List[float], thr: float) -> Optional[float]:\n",
    "    if thr is None: return None\n",
    "    for t, v in zip(times, values):\n",
    "        if v is None or math.isnan(v): continue\n",
    "        if v >= thr: return t\n",
    "    return None\n",
    "\n",
    "def identify_fopdt(times: List[float], Vc: List[float], Ve: List[float], dt_vals: List[float]):\n",
    "    vc_ss = steady_value(Vc); ve_ss = steady_value(Ve)\n",
    "    K = (ve_ss / vc_ss) if (vc_ss and vc_ss > 0) else None\n",
    "    tc = first_crossing(times, Vc, (vc_ss*0.05) if (vc_ss and vc_ss>0) else None)\n",
    "    te = first_crossing(times, Ve, (ve_ss*0.05) if (ve_ss and ve_ss>0) else None)\n",
    "    L = (te - tc) if (tc is not None and te is not None) else None\n",
    "    if L is not None and L < 0: L = 0.0\n",
    "    t63 = first_crossing(times, Ve, (ve_ss*0.632) if ve_ss else None)\n",
    "    tau = (t63 - L) if (t63 is not None and L is not None) else None\n",
    "    if tau is not None and tau < 0: tau = None\n",
    "    mdt = min(dt_vals) if dt_vals else None\n",
    "    if (L is None or L <= 0) and mdt: L = mdt\n",
    "    if (tau is None or tau <= 0) and mdt: tau = mdt\n",
    "    return K, L, tau, vc_ss, ve_ss\n",
    "\n",
    "def zn_pd(K: Optional[float], L: Optional[float], tau: Optional[float]):\n",
    "    if not (K and L and tau) or (K <= 0 or L <= 0 or tau <= 0):\n",
    "        return None, 0.0, None\n",
    "    Kp = 1.2 * (tau / (K * L))\n",
    "    Td = 0.5 * L\n",
    "    Kd = Kp * Td\n",
    "    return Kp, 0.0, Kd\n",
    "\n",
    "def firmware_gains(kp: float, ki: float, kd: float, k_scale: int = 256) -> Tuple[int, int, int]:\n",
    "    return (int(round(kp * k_scale)), int(round(ki * k_scale)), int(round(kd * k_scale)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Checklist de Diagnóstico\n",
    "- Sanitização: linhas suficientes? `id` estrito? eixo único?\n",
    "- Stride: Δt mínimo suficiente? ruído aceitável?\n",
    "- Regime: `v_cmd,ss` e `v_enc,ss` bem definidos? saturações?\n",
    "- Crossings: thresholds atingidos (5% e 63,2%)?\n",
    "- Ganhos: `Kp_safe` estável no simulador? overshoot dentro do alvo?\n",
    "- Firmware: inteiros coerentes com `K_SCALE=256`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Referências\n",
    "- Ziegler, J. G.; Nichols, N. B. (1942). Optimum Settings for Automatic Controllers. Transactions of the ASME, 64, 759–768.\n",
    "- Cohen, G. H.; Coon, G. A. (1953). Theoretical Considerations of Time-Delayed Control. Ind. Eng. Chem., 45(12), 243–251.\n",
    "- Åström, K. J.; Hägglund, T. (1995). PID Controllers: Theory, Design, and Tuning (2nd ed.). ISA.\n",
    "- Åström, K. J.; Murray, R. M. (2008). Feedback Systems: An Introduction for Scientists and Engineers. Princeton Univ. Press.\n",
    "- Seborg, D. E.; Edgar, T. F.; Mellichamp, D. A.; Doyle, F. (2011). Process Dynamics and Control (3rd ed.). Wiley.\n",
    "- Skogestad, S. (2003). Simple analytic rules for model reduction and PID controller tuning. Journal of Process Control, 13(4), 291–309.\n",
    "- Rivera, D. E.; Morari, M.; Skogestad, S. (1986). Internal Model Control. 4. PID controller design. Ind. Eng. Chem. Process Des. Dev., 25(1), 252–265.\n",
    "- Smith, O. J. M. (1957). Close control of loops with dead time. Chemical Engineering Progress, 53(5), 217–219.\n",
    "- Franklin, G. F.; Powell, J. D.; Emami-Naeini, A. (2015). Feedback Control of Dynamic Systems (7th ed.). Pearson.\n",
    "- Ogata, K. (2010). Modern Control Engineering (5th ed.). Prentice Hall."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}