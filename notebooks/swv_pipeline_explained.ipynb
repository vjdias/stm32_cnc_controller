{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline SWV → Ganhos de Controle (Explicado)\n",
    "\n",
    "Este notebook documenta, com fórmulas e exemplos, o fluxo dos seus scripts:\n",
    "\n",
    "1) Exportação SWV e sanitização (`filter_swv_export.py`)\\\n",
    "2) Séries derivadas e métricas (`analyze_step_responses.py`)\\\n",
    "3) Identificação do modelo FOPDT\\\n",
    "4) Síntese dos ganhos PD (Ziegler–Nichols, curva de reação)\\\n",
    "5) Geração do summary e CSVs derivados\\\n",
    "6) Uso dos perfis consolidados por `tuning_profiles.py`\n",
    "\n",
    "Ao final há células de código que demonstram as fórmulas e leitura de amostras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exportação SWV e Sanitização\n",
    "\n",
    "Os dumps SWV/ITM podem conter ruído textual ou linhas truncadas. O script `filter_swv_export.py` padroniza cada arquivo em um CSV com linhas válidas no formato:\n",
    "\n",
    "```\n",
    "axis,id,time_ms,encoder,pulses\n",
    "```\n",
    "\n",
    "Regras de consistência aplicadas (por arquivo):\n",
    "- Aceita apenas linhas numéricas que casam a regex `^\\s*(-?\\d+),(-?\\d+),(-?\\d+),(-?\\d+),(-?\\d+)\\s*$`.\n",
    "- O primeiro `axis` numérico define o eixo do arquivo; todas as linhas seguintes com outro valor são descartadas.\n",
    "- `id` precisa ser estritamente crescente (cada linha nova: `seq > last_id`).\n",
    "- `time_ms` e `pulses` não podem andar para trás (`t_ms >= last_time` e `pulses >= last_pulses`).\n",
    "- O valor de `encoder` é tomado em módulo (sempre positivo).\n",
    "- Arquivos que não preservam nenhuma linha são descartados (arquivo de saída apagado).\n",
    "\n",
    "Resultado: `*_filtered.csv` sob `CNC_Controller/SWV_export/` (ou diretório indicado)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Séries Derivadas (Velocidades)\n",
    "\n",
    "A partir de `axis,id,time_ms,encoder,pulses`, calculam-se velocidades por diferenças finitas. Há dois caminhos no script de análise:\n",
    "\n",
    "- Série bruta: usa pares adjacentes (linha `k` e `k-1`) para computar intervalos `Δt_k`. Linhas com `Δt_k <= 0` são ignoradas.\n",
    "- Série derivada com janela deslizante (stride): usa a primeira e a última linha de uma janela de `N` amostras válidas para reduzir ruído.\n",
    "\n",
    "Definições (com tempo em segundos):\n",
    "\n",
    "$\\displaystyle t_k = \tfrac{time\\_ms(k)}{1000}$\\\n",
    "$\\displaystyle \\Delta t_k = t_k - t_{k-N+1}$ (janela)\\\n",
    "$\\displaystyle v_{cmd}(k) = \tfrac{pulses(k) - pulses(k-N+1)}{\\Delta t_k}$\\\n",
    "$\\displaystyle v_{enc}(k) = \tfrac{encoder(k) - encoder(k-N+1)}{\\Delta t_k}$\n",
    "\n",
    "O tamanho da janela `N` (parâmetro `--stride`, padrão 10) suaviza as derivadas preservando a detecção do degrau.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Identificação FOPDT\n",
    "\n",
    "Assume-se o modelo de primeira ordem com atraso (FOPDT) para a malha de velocidade:\n",
    "\n",
    "$\\displaystyle G_v(s) = rac{K \\; e^{-Ls}}{\\tau s + 1}$\n",
    "\n",
    "- Ganho estático: $K = \\tfrac{v_{enc,ss}}{v_{cmd,ss}}$, onde `ss` é valor médio no regime estacionário (janela final).\n",
    "- Atraso puro: $L$ é estimado pela diferença entre os instantes em que `v_cmd` e `v_enc` cruzam 5% dos seus respectivos valores de regime: $L = t_{enc}^{5\\%} - t_{cmd}^{5\\%}$.\n",
    "- Constante de tempo: $\\tau$ usa o cruzamento a 63,2% de `v_enc`: $t_{63} =$ primeiro instante em que `v_enc(t) \\ge 0,632 \\cdot v_{enc,ss}` e $\\tau = t_{63} - L$.\n",
    "\n",
    "Tratamento de borda e resolução temporal:\n",
    "- Se $L \\le 0$ ou indefinido, usa-se a menor `Δt` observada nos dados (`min_dt_raw`) como piso para $L$.\n",
    "- Se $\\tau \\le 0$ ou indefinido, igualmente usa-se `min_dt_raw`.\n",
    "- Valores inválidos (NaN/inf) são descartados.\n",
    "\n",
    "Classificação de forma do degrau (opcional): compara o tempo até 90% com a duração total; rotula *step-like* se a subida for curta (≤ 15% do total) ou *ramp-like* caso contrário."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Síntese de Ganhos (Ziegler–Nichols, Curva de Reação)\n",
    "\n",
    "O controlador usado aqui é PD na malha de velocidade (Ki = 0, pois a malha de posição já integra). As regras de Z–N para curva de reação aplicadas são:\n",
    "\n",
    "$\\displaystyle K_p = 1.2 \\cdot rac{\\tau}{K \\cdot L}$\\\n",
    "$\\displaystyle T_d = 0.5 \\cdot L$\\\n",
    "$\\displaystyle K_d = K_p \\cdot T_d$\\\n",
    "\n",
    "Sugestão segura: usar inicialmente $K_p/2$ e aumentar gradualmente até $K_p$ caso a resposta comporte-se bem.\n",
    "\n",
    "Conversão para inteiros do firmware (escala `K_SCALE = 256`):\\\n",
    "$\\displaystyle kp_i = \\mathrm{round}(K_p \\cdot 256)$,\\\n",
    "$\\displaystyle ki_i = \\mathrm{round}(K_i \\cdot 256)$,\\\n",
    "$\\displaystyle kd_i = \\mathrm{round}(K_d \\cdot 256)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary e CSVs Derivados\n",
    "\n",
    "O script `analyze_step_responses.py` gera:\n",
    "- Um relatório consolidado `analysis_summary.txt` sob `CNC_Controller/SWV_export`, contendo para cada arquivo analisado as métricas e os ganhos PD.\n",
    "- (Opcional) CSVs derivados por arquivo (em `analysis_data/`), contendo `time_s`, `delta_t_s`, `vel_cmd_sps`, `vel_enc_sps` e outros campos úteis para inspeção/plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Integração com tuning_profiles.py\n",
    "\n",
    "Os valores validados do summary alimentam uma tabela no `tuning_profiles.py` associada a pares (eixo, microstep). Cada entrada guarda $(K_p, K_i, K_d, L, \\tau)$ e os valores de regime. Os simuladores (`fopdt_simulator.py`, `interactive_sim.py`) consomem essa tabela e convertem para inteiros de firmware com a escala 256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilitários demonstrativos das fórmulas usadas no pipeline\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import csv, math\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "\n",
    "def load_filtered_rows(csv_path: Path) -> List[Dict[str, int]]:\n",
    "    rows: List[Dict[str, int]] = []\n",
    "    with csv_path.open('r', encoding='utf-8', newline='') as fh:\n",
    "        reader = csv.reader(fh)\n",
    "        for cols in reader:\n",
    "            if len(cols) < 5:\n",
    "                continue\n",
    "            try:\n",
    "                axis = int(cols[0]); seq = int(cols[1]); t_ms = int(cols[2])\n",
    "                encoder = int(cols[3]); pulses = int(cols[4])\n",
    "            except ValueError:\n",
    "                continue\n",
    "            rows.append({'axis': axis, 'seq': seq, 'time_ms': t_ms, 'encoder': encoder, 'pulses': pulses})\n",
    "    return rows\n",
    "\n",
    "def compute_raw_series(rows: List[Dict[str, int]]):\n",
    "    T: List[float] = []\n",
    "    Vc: List[float] = []\n",
    "    Ve: List[float] = []\n",
    "    dt_vals: List[float] = []\n",
    "    prev = None\n",
    "    for r in rows:\n",
    "        if prev is None:\n",
    "            prev = r; continue\n",
    "        dt_ms = r['time_ms'] - prev['time_ms']\n",
    "        if dt_ms <= 0:\n",
    "            prev = r; continue\n",
    "        dt = dt_ms / 1000.0\n",
    "        dp = r['pulses'] - prev['pulses']\n",
    "        de = r['encoder'] - prev['encoder']\n",
    "        Vc.append(dp / dt if dt != 0 else math.nan)\n",
    "        Ve.append(de / dt if dt != 0 else math.nan)\n",
    "        T.append(r['time_ms'] / 1000.0)\n",
    "        dt_vals.append(dt)\n",
    "        prev = r\n",
    "    return T, Vc, Ve, dt_vals\n",
    "\n",
    "def steady_value(values: List[float], frac: float = 0.2) -> Optional[float]:\n",
    "    if not values:\n",
    "        return None\n",
    "    start = max(0, len(values) - max(1, int(len(values) * frac)))\n",
    "    window = [v for v in values[start:] if (v is not None and not math.isnan(v))]\n",
    "    if not window:\n",
    "        window = [v for v in values if (v is not None and not math.isnan(v))]\n",
    "    if not window:\n",
    "        return None\n",
    "    return sum(window) / len(window)\n",
    "\n",
    "def first_crossing(times: List[float], values: List[float], thr: float) -> Optional[float]:\n",
    "    if thr is None:\n",
    "        return None\n",
    "    for t, v in zip(times, values):\n",
    "        if v is None or math.isnan(v):\n",
    "            continue\n",
    "        if v >= thr:\n",
    "            return t\n",
    "    return None\n",
    "\n",
    "def identify_fopdt(times: List[float], Vc: List[float], Ve: List[float], dt_vals: List[float]):\n",
    "    steady_cmd = steady_value(Vc)\n",
    "    steady_enc = steady_value(Ve)\n",
    "    K = (steady_enc / steady_cmd) if steady_cmd and steady_cmd > 0 else None\n",
    "    cmd_thr = (steady_cmd * 0.05) if steady_cmd and steady_cmd > 0 else None\n",
    "    enc_thr = (steady_enc * 0.05) if steady_enc and steady_enc > 0 else None\n",
    "    t_cmd = first_crossing(times, Vc, cmd_thr) if cmd_thr else None\n",
    "    t_enc = first_crossing(times, Ve, enc_thr) if enc_thr else None\n",
    "    L = (t_enc - t_cmd) if (t_cmd is not None and t_enc is not None) else None\n",
    "    if L is not None and L < 0: L = 0.0\n",
    "    t63_target = (steady_enc * 0.632) if steady_enc else None\n",
    "    t63 = first_crossing(times, Ve, t63_target) if t63_target else None\n",
    "    tau = (t63 - L) if (t63 is not None and L is not None) else None\n",
    "    if tau is not None and tau < 0: tau = None\n",
    "    min_dt = min(dt_vals) if dt_vals else None\n",
    "    if (L is None or L <= 0) and min_dt: L = min_dt\n",
    "    if (tau is None or tau <= 0) and min_dt: tau = min_dt\n",
    "    return K, L, tau, steady_cmd, steady_enc\n",
    "\n",
    "def zn_pd(K: Optional[float], L: Optional[float], tau: Optional[float]):\n",
    "    if not (K and L and tau) or (K <= 0 or L <= 0 or tau <= 0):\n",
    "        return None, 0.0, None\n",
    "    Kp = 1.2 * (tau / (K * L))\n",
    "    Td = 0.5 * L\n",
    "    Kd = Kp * Td\n",
    "    return Kp, 0.0, Kd\n",
    "\n",
    "def firmware_gains(kp: float, ki: float, kd: float, k_scale: int = 256) -> Tuple[int,int,int]:\n",
    "    return (int(round(kp * k_scale)), int(round(ki * k_scale)), int(round(kd * k_scale)))\n",
    "\n",
    "print('Funções carregadas.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstração: tenta carregar o primeiro *_filtered.csv e calcular K, L, tau e ganhos PD\n",
    "base = Path.cwd() / 'CNC_Controller' / 'SWV_export'\n",
    "candidates = sorted(base.glob('*_filtered.csv')) if base.exists() else []\n",
    "if not candidates:\n",
    "    print('Nenhum *_filtered.csv encontrado sob CNC_Controller/SWV_export — rode filter_swv_export.py e analyze_step_responses.py.')\n",
    "else:\n",
    "    sample = candidates[0]\n",
    "    print('Exemplo:', sample.name)\n",
    "    rows = load_filtered_rows(sample)\n",
    "    T, Vc, Ve, dt_vals = compute_raw_series(rows)\n",
    "    K, L, tau, Vc_ss, Ve_ss = identify_fopdt(T, Vc, Ve, dt_vals)\n",
    "    Kp, Ki, Kd = zn_pd(K, L, tau)\n",
    "    print(f'K={K}, L={L}, tau={tau}')\n",
    "    if Kp is not None:\n",
    "        print(f'Z–N PD: Kp={Kp:.4f}, Ki={Ki:.4f}, Kd={Kd:.4f}')\n",
    "        print('Firmware ints:', firmware_gains(Kp, Ki, Kd))\n",
    "    else:\n",
    "        print('Não foi possível sintetizar ganhos (dados insuficientes).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como reproduzir pelo terminal\n",
    "\n",
    "1. Sanitizar: `python filter_swv_export.py`\\\n",
    "2. Analisar: `python analyze_step_responses.py -v`\\\n",
    "3. Simular: `python fopdt_simulator.py --axes X:256,Y:16,Z:256 --plot --emit-fw`\\\n",
    "4. Atualizar `tuning_profiles.py` com os novos valores, se desejar consolidá-los."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
